{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef6231d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\"> <h1>Assignment 20</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae7adb",
   "metadata": {},
   "source": [
    "<h2 style='text-align: left;'> Assignment Questions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aca734",
   "metadata": {},
   "source": [
    "<h3 style='text-align: left;'> 1.  What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82bad49",
   "metadata": {},
   "source": [
    "<p> <b> Ans:- <br><br> Web Scrapping:- <br><br> Web scraping is an automatic method to obtain large amounts of data from websites. <br> Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.<br> There are many different ways to perform web scraping to obtain data from websites. <br> These include using online services, particular API’s or even creating your code for web scraping from scratch. <br> Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. <br> This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data. <br><br> Web scraping requires two parts, namely the crawler and the scraper.<br><br> The crawler is an artificial intelligence algorithm that browses the web to search for the particular data required by following the links across the internet. <br><br> The scraper, on the other hand, is a specific tool created to extract data from the website. <br><br> The design of the scraper can vary greatly according to the complexity and scope of the project so that it can quickly and accurately extract the data. <br><br> Some tasks you can automate through the use of web scraping include comparing financial reports, gathering email addresses, statistical research, price comparison, finding job listings and more.<br><br> Web Scraping has multiple applications across various industries. Let’s check out some of these now!<br><br> 1. Price Monitoring <br><br>Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue. <br><br> 2. Market Research <br><br>Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. <br><br> 3. News Monitoring<br><br>Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day! <br><br> 4. Sentiment Analysis <br><br> If companies want to understand the general sentiment for their products among their consumers, then Sentiment Analysis is a must. Companies can use web scraping to collect data from social media websites such as Facebook and Twitter as to what the general sentiment about their products is. This will help them in creating products that people desire and moving ahead of their competition. <br><br> 5. Email Marketing <br><br> Companies can also use Web scraping for email marketing. They can collect Email ID’s from various sites using web scraping and then send bulk promotional and marketing Emails to all the people owning these Email ID’s.</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8121dd0",
   "metadata": {},
   "source": [
    "<h3 style='text-align: left;'> 2. What are the different methods used for Web Scraping? </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209f8f2",
   "metadata": {},
   "source": [
    "<p> <b> Ans:- <br><br> Web scraping is the process of extracting data from websites. There are several methods that can be used for web scraping, including: <br><br> 1. Manual scraping: <br> This involves manually copying and pasting data from websites into a spreadsheet or other document. <br><br> 2. Parsing HTML: <br> This involves using programming languages like Python or JavaScript to parse the HTML code of a webpage and extract data. <br><br> 3. Web scraping tools: <br> There are many tools available that can be used for web scraping, such as BeautifulSoup, Scrapy, and Selenium. These tools can automate the process of extracting data from websites. <br><br> 4. APIs: <br> Some websites provide APIs (Application Programming Interfaces) that allow developers to access their data in a structured format. <br><br> 5. Browser extensions: <br> There are also browser extensions, such as Web Scraper and Data Miner, that can be used to scrape data from websites. <br><br> It's important to note that while web scraping can be a powerful tool for collecting data, it's also important to respect website terms of use and legal guidelines for web scraping. </b></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8858109",
   "metadata": {},
   "source": [
    "<h3 style='text-align: left;'> 3. What is Beautiful Soup? Why is it used? </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ae8723",
   "metadata": {},
   "source": [
    "<p><b> Ans:- <br><br> Beautiful Soup is a Python library that is commonly used for web scraping. It is a popular tool because it simplifies the process of parsing and navigating HTML and XML documents, making it easier to extract data from websites. <br><br> Beautiful Soup allows developers to search for and extract specific elements from a webpage based on their HTML tags, attributes, and class names. It also provides useful features for handling malformed HTML and encoding issues. <br><br> Some of the key features of Beautiful Soup include: <br><br> 1. A simple and intuitive API: <br> Beautiful Soup provides an easy-to-use API for parsing HTML and XML documents. <br><br> 2. Powerful search capabilities: <br> Developers can use Beautiful Soup to search for specific elements on a webpage based on their HTML tags, attributes, and class names. <br><br> 3. Support for different parsers: <br> Beautiful Soup supports different HTML and XML parsers, including lxml, html5lib, and the built-in Python parser. <br><br> 4. Navigational tools: <br> Beautiful Soup provides navigational tools like find, find_all, and select, which allow developers to search for specific elements based on various criteria. <br><br> 5. Handling of errors and inconsistencies: <br> Beautiful Soup is designed to handle errors and inconsistencies in HTML and XML documents, making it more resilient to changes in website structure. <br><br> Overall, Beautiful Soup is a powerful and flexible tool for web scraping that simplifies the process of extracting data from websites. </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b352fc",
   "metadata": {},
   "source": [
    "<h3 style='text-align: left;'> 4. Why is flask used in this Web Scraping project? </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46432fe8",
   "metadata": {},
   "source": [
    "<p><b> Ans:- <br><br> Flask is a Python web framework that is often used for building web applications and APIs. Flask is commonly used in web scraping projects because it provides a lightweight and flexible way to serve scraped data over the web. <br><br> In a web scraping project, Flask can be used to create a RESTful API that allows other applications to access the scraped data. Flask can also be used to create a web interface for the scraped data, allowing users to view and interact with the data directly in a web browser. <br><br> Here are some of the key reasons why Flask is a popular choice for web scraping projects: <br><br> 1. Lightweight and flexible: <br> Flask is a lightweight and flexible web framework that can be easily adapted to different web scraping projects. <br><br> 2. Easy to use: <br> Flask has a simple and intuitive API that makes it easy to create web applications and APIs. <br><br> 3. Extensible: <br> Flask provides a number of extensions that can be used to add additional functionality to web scraping projects, such as support for databases, authentication, and caching. <br><br> 4. Easy to deploy: <br> Flask can be easily deployed to a variety of hosting platforms, such as Heroku, AWS, or Google Cloud, making it easy to share scraped data with others. <br><br> Overall, Flask is a popular choice for web scraping projects because it provides a simple and flexible way to serve scraped data over the web. </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4f5206",
   "metadata": {},
   "source": [
    "<h3 style='text-align: left;'> 5. Write the names of AWS services used in this project. Also, explain the use of each service. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4671a6",
   "metadata": {},
   "source": [
    "<p><b> Ans:- <br><br> AWS services used in this project:- <br><br> 1. Elastic Beanstalk:- <br> Elastic Beanstalk is a fully managed service that simplifies the process of deploying and scaling web applications. It provides a platform for developers to deploy and manage web applications without worrying about the underlying infrastructure, such as EC2 instances, load balancing, and scaling. <br><br> 2. CodePipeline:- <br> CodePipeline is a continuous delivery service that automates the release process for applications and services. It provides a workflow that automates the building, testing, and deploying of code changes, making it easier to release new features and updates to web applications. <br><br> Overall, Elastic Beanstalk and CodePipeline provide a powerful platform for deploying and managing web applications, making it easier and faster for developers to release new features and updates. </b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36a38e",
   "metadata": {},
   "source": [
    "<h4 style='text-align: right;'><b> Yash Sanjeev Halwai </b> </h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
